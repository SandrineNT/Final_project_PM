{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 440,
      "metadata": {
        "id": "zRBGGQH7JNbb"
      },
      "outputs": [],
      "source": [
        "# Imports librairies\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import nltk\n",
        "import os\n",
        "import pandas as pd\n",
        "from os import getcwd\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from datasets import load_dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    import datasets\n",
        "except ModuleNotFoundError:\n",
        "    !pip install datasets\n",
        "    import datasets"
      ],
      "metadata": {
        "id": "IUSPpGNhGz1P"
      },
      "execution_count": 441,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    from unidecode import unidecode\n",
        "except ModuleNotFoundError:\n",
        "    !pip install unidecode\n",
        "    from unidecode import unidecode"
      ],
      "metadata": {
        "id": "vWy5FoIxzNI7"
      },
      "execution_count": 442,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load my data\n",
        "Data_reddit = pd.read_csv(\"Reddit_Data.csv\")\n",
        "Data_twitter = pd.read_csv(\"Twitter_Data.csv\")\n",
        "Data_twitter.rename(columns = {'clean_text':'clean_comment'}, inplace = True)\n",
        "Data = Data_reddit.append(Data_twitter).reset_index()"
      ],
      "metadata": {
        "id": "FQSmK-89JW60"
      },
      "execution_count": 443,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrU-t0J8BMEK",
        "outputId": "ab40ea9e-e7a7-45f9-e4e9-9dbf696704db"
      },
      "execution_count": 444,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         index                                      clean_comment  category\n",
            "0            0   family mormon have never tried explain them t...       1.0\n",
            "1            1  buddhism has very much lot compatible with chr...       1.0\n",
            "2            2  seriously don say thing first all they won get...      -1.0\n",
            "3            3  what you have learned yours and only yours wha...       0.0\n",
            "4            4  for your own benefit you may want read living ...       1.0\n",
            "...        ...                                                ...       ...\n",
            "200224  162975  why these 456 crores paid neerav modi not reco...      -1.0\n",
            "200225  162976  dear rss terrorist payal gawar what about modi...      -1.0\n",
            "200226  162977  did you cover her interaction forum where she ...       0.0\n",
            "200227  162978  there big project came into india modi dream p...       0.0\n",
            "200228  162979  have you ever listen about like gurukul where ...       1.0\n",
            "\n",
            "[200229 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Rename our label\n",
        "def rename(val):\n",
        "    if val == -1:\n",
        "        return \"Negative\"\n",
        "    elif val == 0:\n",
        "        return \"Neutral\"\n",
        "    elif val ==1:\n",
        "        return \"Positive\""
      ],
      "metadata": {
        "id": "hE1Wwl2C5p3X"
      },
      "execution_count": 445,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Data['category'] = Data['category'].apply(rename)\n",
        "#shuffling the data\n",
        "Data = Data.sample(frac=1)"
      ],
      "metadata": {
        "id": "ZHko2zTY5tBf"
      },
      "execution_count": 446,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Drop null value\n",
        "Data = Data.dropna()\n",
        "Data.shape"
      ],
      "metadata": {
        "id": "-gVNFSqH5-fo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "542517b2-6b51-4a25-f6e7-0ad41d76733e"
      },
      "execution_count": 447,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200118, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 447
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Select the comment\n",
        "X= Data['clean_comment']"
      ],
      "metadata": {
        "id": "4vQ1_yb7ChJ4"
      },
      "execution_count": 448,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Select the label\n",
        "Y = pd.get_dummies(Data['category'],\n",
        "                   columns=Data[\"category\"]).values"
      ],
      "metadata": {
        "id": "8QLBYnLNB5AX"
      },
      "execution_count": 449,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a vectorization layer\n",
        "max_features = 1000  # Maximum vocab size.\n",
        "max_len = 4  # Sequence length to pad the outputs to.\n",
        "vectorize_layer = tf.keras.layers.TextVectorization(\n",
        " max_tokens=max_features,\n",
        " output_mode='int',\n",
        " output_sequence_length=max_len)"
      ],
      "metadata": {
        "id": "1HlAr7xs9eSh"
      },
      "execution_count": 450,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Adapt the vector\n",
        "clean_comment = X['clean_comment'].values.tolist()\n",
        "text_dataset = tf.data.Dataset.from_tensor_slices(clean_comment )\n",
        "text_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Y2h0USbDJmD",
        "outputId": "68557f2e-afad-4480-d3f9-29302481f6b4"
      },
      "execution_count": 451,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.string, name=None)>"
            ]
          },
          "metadata": {},
          "execution_count": 451
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorize_layer.adapt(text_dataset.batch(64))"
      ],
      "metadata": {
        "id": "C3q0s9EIC5GZ"
      },
      "execution_count": 452,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = np.array(vectorize_layer.get_vocabulary())\n",
        "vocab[:50]"
      ],
      "metadata": {
        "id": "eFVK8Xkb9bfb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c2f1263-51f0-408b-a5f7-cbf821de140d"
      },
      "execution_count": 453,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['', '[UNK]', 'the', 'and', 'that', 'this', 'for', 'you', 'are',\n",
              "       'they', 'not', 'have', 'with', 'but', 'will', 'was', 'people',\n",
              "       'what', 'india', 'all', 'modi', 'bjp', 'has', 'can', 'like',\n",
              "       'from', 'about', 'just', 'there', 'who', 'their', 'one', 'his',\n",
              "       'good', 'how', 'more', 'don', 'would', 'now', 'your', 'same',\n",
              "       'them', 'when', 'even', 'some', 'out', 'get', 'any', 'because',\n",
              "       'only'], dtype='<U14')"
            ]
          },
          "metadata": {},
          "execution_count": 453
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create the embedding layers\n",
        "SEED = 34\n",
        "\n",
        "# set seed for reproducibility\n",
        "tf.keras.utils.set_random_seed(SEED)\n",
        "\n",
        "embedding = tf.keras.layers.Embedding(\n",
        "        input_dim = len(vocab) ,\n",
        "        output_dim = 6,# Use masking to handle the variable sequence lengths\n",
        "        mask_zero=True)"
      ],
      "metadata": {
        "id": "0CnUrOYX9UYt"
      },
      "execution_count": 454,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set seed for reproducibility\n",
        "tf.keras.utils.set_random_seed(SEED)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    vectorize_layer,\n",
        "    embedding,\n",
        "    tf.keras.layers.Normalization(axis=None),\n",
        "    tf.keras.layers.SpatialDropout1D(0.2),\n",
        "    tf.keras.layers.LSTM(100, dropout=0.2, recurrent_dropout=0.2),\n",
        "    tf.keras.layers.Dense(units = 64, activation = 'relu'),\n",
        "    tf.keras.layers.Dense(3, activation= \"sigmoid\")\n",
        "])"
      ],
      "metadata": {
        "id": "8oxPCzCg8cpQ"
      },
      "execution_count": 455,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "-y_bBdVWELDr"
      },
      "execution_count": 456,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CyVF4fdUDuaH",
        "outputId": "27ca596e-3371-4948-ea05-210ea239292f"
      },
      "execution_count": 457,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " text_vectorization_10 (Text  (None, 4)                0         \n",
            " Vectorization)                                                  \n",
            "                                                                 \n",
            " embedding_10 (Embedding)    (None, 4, 6)              6000      \n",
            "                                                                 \n",
            " normalization_2 (Normalizat  (None, 4, 6)             3         \n",
            " ion)                                                            \n",
            "                                                                 \n",
            " spatial_dropout1d_3 (Spatia  (None, 4, 6)             0         \n",
            " lDropout1D)                                                     \n",
            "                                                                 \n",
            " lstm_14 (LSTM)              (None, 100)               42800     \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 64)                6464      \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 3)                 195       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 55,462\n",
            "Trainable params: 55,459\n",
            "Non-trainable params: 3\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_x, test_x , train_y, test_y = train_test_split(X, Y, test_size=.3)\n"
      ],
      "metadata": {
        "id": "TRFrolUpDuc3"
      },
      "execution_count": 458,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dictionary to keep history output from fit calls\n",
        "logs = {}\n",
        "\n",
        "# directory in which model checkpoints and logs are saved\n",
        "LOG_DIR = 'logs'\n",
        "\n",
        "def best_model_path(model_name):\n",
        "    base_dir  = os.path.join(LOG_DIR, model_name)\n",
        "    return os.path.join(base_dir, 'best_val_accuracy.ckpt')\n",
        "\n",
        "def callback_list(model_name):\n",
        "    base_dir  = os.path.join(LOG_DIR, model_name)\n",
        "    tb_cb = tf.keras.callbacks.TensorBoard(base_dir)\n",
        "    ckpt = tf.keras.callbacks.ModelCheckpoint(\n",
        "         best_model_path(model_name),\n",
        "         monitor='val_accuracy',\n",
        "         mode='max', \n",
        "         verbose=0,\n",
        "         save_best_only=True)\n",
        "    backup_dir = os.path.join(base_dir, 'backup_checkpoint')\n",
        "    bkp = tf.keras.callbacks.BackupAndRestore(\n",
        "        backup_dir)\n",
        "    return [tb_cb, ckpt, bkp]"
      ],
      "metadata": {
        "id": "pfA9IO3yFKM5"
      },
      "execution_count": 459,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "MODEL_NAME = 'LSTM'\n",
        "history = model.fit(train_x, train_y, epochs=30,\n",
        "                    batch_size=32,\n",
        "                    validation_split=0.15, \n",
        "                    callbacks=callback_list(MODEL_NAME))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXj0Xb2DDufz",
        "outputId": "4e0f349e-ef01-4a38-fa6b-d2c9a92e9554"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/30\n",
            " 617/3721 [===>..........................] - ETA: 37s - loss: 0.8904 - accuracy: 0.5505"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Test our model\n",
        "from datasets import load_dataset\n",
        "best_m=tf.keras.models.load_model( best_model_path('LSTM'))\n",
        "my_review=[unidecode(\"J'ai détesté ce livre.\")]\n",
        "best_m.predict(my_review)"
      ],
      "metadata": {
        "id": "1HQgzBgiDuh9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.utils.set_random_seed(SEED)\n",
        "\n",
        "model2 = tf.keras.Sequential([\n",
        "    vectorize_layer,\n",
        "    embedding,\n",
        "    tf.keras.layers.Normalization(axis=None),\n",
        "    tf.keras.layers.SpatialDropout1D(0.2),\n",
        "    tf.keras.layers.LSTM(100, dropout=0.2, recurrent_dropout=0.2),\n",
        "    tf.keras.layers.LSTM(64,return_sequences=True)\n",
        "    tf.keras.layers.Dense(units = 64, activation = 'relu'),\n",
        "    tf.keras.layers.Dense(units = 32, activation = 'relu'),\n",
        "    tf.keras.layers.Dense(3, activation= \"sigmoid\")\n",
        "])"
      ],
      "metadata": {
        "id": "4fpl6WJ7N4tm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = 'Stack2LSTM'\n",
        "logs[MODEL_NAME] = model2.fit(\n",
        "    # TODO complete the fit call\n",
        "    train_x,train_y, epochs=50,\n",
        "    validation_data=0.15,\n",
        "    callbacks=callback_list(MODEL_NAME)\n",
        "    )"
      ],
      "metadata": {
        "id": "XGLp5oNMJd1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test our model\n",
        "from datasets import load_dataset\n",
        "best_m=tf.keras.models.load_model( best_model_path('LSTM'))\n",
        "my_review=[unidecode(\"J'ai détesté ce livre.\")]\n",
        "best_m.predict(my_review)"
      ],
      "metadata": {
        "id": "r5SNbz-dK-hD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs"
      ],
      "metadata": {
        "id": "RZyP32ZhOr4R"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}